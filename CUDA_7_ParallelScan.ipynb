{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile common.h\n",
        "\n",
        "#ifndef COMMON_H\n",
        "#define COMMON_H\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cstring>\n",
        "#include <time.h>\n",
        "#include <stdlib.h>\n",
        "#include <utime.h>\n",
        "#include <fstream>\n",
        "\n",
        "#define HANDLE_NULL( a ){if (a == NULL) { \\\n",
        "                            printf( \"Host memory failed in %s at line %d\\n\", \\\n",
        "                                    __FILE__, __LINE__ ); \\\n",
        "                            exit( EXIT_FAILURE );}}\n",
        "\n",
        "enum INIT_PARAM{\n",
        "\tINIT_ZERO,INIT_RANDOM,INIT_ONE,INIT_ONE_TO_TEN,INIT_FOR_SPARSE_METRICS,INIT_0_TO_X\n",
        "};\n",
        "\n",
        "//simple initialization\n",
        "void initialize(int * input, const int array_size,\n",
        "\tINIT_PARAM PARAM = INIT_ONE_TO_TEN, int x = 0);\n",
        "\n",
        "void initialize(float * input, const int array_size,\n",
        "\tINIT_PARAM PARAM = INIT_ONE_TO_TEN);\n",
        "\n",
        "void launch_dummmy_kernel();\n",
        "\n",
        "//compare two arrays\n",
        "void compare_arrays(int * a, int * b, int size);\n",
        "\n",
        "//reduction in cpu\n",
        "int reduction_cpu(int * input, const int size);\n",
        "\n",
        "//compare results\n",
        "void compare_results(int gpu_result, int cpu_result);\n",
        "\n",
        "//print array\n",
        "void print_array(int * input, const int array_size);\n",
        "\n",
        "//print array\n",
        "void print_array(float * input, const int array_size);\n",
        "\n",
        "//print matrix\n",
        "void print_matrix(int * matrix, int nx, int ny);\n",
        "\n",
        "void print_matrix(float * matrix, int nx, int ny);\n",
        "\n",
        "//get matrix\n",
        "int* get_matrix(int rows, int columns);\n",
        "\n",
        "//matrix transpose in CPU\n",
        "void mat_transpose_cpu(int * mat, int * transpose, int nx, int ny);\n",
        "\n",
        "//print_time_using_host_clock\n",
        "void print_time_using_host_clock(clock_t start, clock_t end);\n",
        "\n",
        "void printData(char *msg, int *in, const int size);\n",
        "\n",
        "void compare_arrays(float * a, float * b, float size);\n",
        "\n",
        "void sum_array_cpu(float* a, float* b, float *c, int size);\n",
        "\n",
        "void print_arrays_toafile(int*, int , char* );\n",
        "\n",
        "void print_arrays_toafile_side_by_side(float*,float*,int,char*);\n",
        "\n",
        "void print_arrays_toafile_side_by_side(int*, int*, int, char*);\n",
        "\n",
        "#endif // !COMMON_H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LI7eR4VZ3NC",
        "outputId": "1ccb2a81-871e-42fb-c852-fc0b4e697be7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing common.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cuda_common.cuh\n",
        "\n",
        "#ifndef CUDA_COMMON_H\n",
        "#define CUDA_COMMON_H\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort = true)\n",
        "{\n",
        "\tif (code != cudaSuccess)\n",
        "\t{\n",
        "\t\tfprintf(stderr, \"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "\t\tif (abort) exit(code);\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void scan_efficient_1G(int * input, int* auxiliry_array, int input_size);\n",
        "__global__ void scan_summation(int * input, int * auxiliry_array, int input_size);\n",
        "\n",
        "#endif // !CUDA_COMMON_H\n",
        "\n",
        "//void query_device();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lNTjSPZZ280",
        "outputId": "31916e16-ff8d-4989-cc69-e714fc4fea58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_common.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scan.cuh\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include \"common.h\"\n",
        "#include \"cuda_common.cuh\"\n",
        "\n",
        "//inclusive scan sequential implementation\n",
        "void scan_inclusive_cpu(float*,float*, int);\n",
        "\n",
        "\n",
        "//inclusive scan parallel inefficient implementation\n",
        "__global__ void scan_inclusive_gpu(float*, float*, int );"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLxbwcrsZ2uO",
        "outputId": "bd1c137a-dfd4-4ae2-d59b-a373bc78fad7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scan.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOeqVBGAU374",
        "outputId": "4de45fe9-6b9f-4501-fd8e-0aad80a572dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting one.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile one.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "\n",
        "#define BLOCK_SIZE 512\n",
        "\n",
        "// GPU error checking macro\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort = true)\n",
        "{\n",
        "    if (code != cudaSuccess)\n",
        "    {\n",
        "        fprintf(stderr, \"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "        if (abort) exit(code);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Initialize array with ones\n",
        "void initialize(int *input, const int array_size) {\n",
        "    for (int i = 0; i < array_size; i++) {\n",
        "        input[i] = 1;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Compare two arrays\n",
        "void compare_arrays(int *a, int *b, int size) {\n",
        "    bool match = true;\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        if (a[i] != b[i]) {\n",
        "            printf(\"Arrays don't match at index %d: a[%d]=%d, b[%d]=%d\\n\", i, i, a[i], i, b[i]);\n",
        "            match = false;\n",
        "            if (i > 10) break; // Don't spam too many differences\n",
        "        }\n",
        "    }\n",
        "    if (match) {\n",
        "        printf(\"Arrays match!\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "// Print array (for debugging)\n",
        "void print_array(int *input, const int array_size) {\n",
        "    printf(\"Array: \");\n",
        "    for (int i = 0; i < array_size && i < 20; i++) { // Limit output\n",
        "        printf(\"%d \", input[i]);\n",
        "    }\n",
        "    if (array_size > 20) printf(\"...\");\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "// CPU inclusive scan implementation\n",
        "void inclusive_scan_cpu(int *input, int *output, int size) {\n",
        "    output[0] = input[0];\n",
        "    for (int i = 1; i < size; i++) {\n",
        "        output[i] = output[i-1] + input[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Naive GPU inclusive scan (has race conditions - for demonstration only)\n",
        "__global__ void naive_inclusive_scan(int *input, int size) {\n",
        "    int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (gid < size) {\n",
        "        for (int offset = 1; offset <= gid; offset *= 2) {\n",
        "            if (gid >= offset) {\n",
        "                input[gid] += input[gid - offset];\n",
        "            }\n",
        "            __syncthreads();\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Better GPU inclusive scan using shared memory\n",
        "__global__ void inclusive_scan_gpu(int *input, int *output, int size) {\n",
        "    extern __shared__ int temp[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Load input into shared memory\n",
        "    if (gid < size) {\n",
        "        temp[tid] = input[gid];\n",
        "    } else {\n",
        "        temp[tid] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Perform scan in shared memory\n",
        "    for (int offset = 1; offset < blockDim.x; offset *= 2) {\n",
        "        int temp_val = 0;\n",
        "        if (tid >= offset && tid < blockDim.x) {\n",
        "            temp_val = temp[tid - offset];\n",
        "        }\n",
        "        __syncthreads();\n",
        "\n",
        "        if (tid >= offset && tid < blockDim.x) {\n",
        "            temp[tid] += temp_val;\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write result to output\n",
        "    if (gid < size) {\n",
        "        output[gid] = temp[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char**argv)\n",
        "{\n",
        "    printf(\"Scan algorithm execution started\\n\");\n",
        "\n",
        "    int input_size = 1 << 10; // Default 1024 elements\n",
        "\n",
        "    if (argc > 1) {\n",
        "        input_size = 1 << atoi(argv[1]);\n",
        "    }\n",
        "\n",
        "    printf(\"Input size: %d elements\\n\", input_size);\n",
        "\n",
        "    const int byte_size = sizeof(int) * input_size;\n",
        "\n",
        "    // Host memory allocation\n",
        "    int *h_input = (int*)malloc(byte_size);\n",
        "    int *h_output_cpu = (int*)malloc(byte_size);\n",
        "    int *h_output_gpu = (int*)malloc(byte_size);\n",
        "\n",
        "    if (!h_input || !h_output_cpu || !h_output_gpu) {\n",
        "        printf(\"Host memory allocation failed\\n\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Initialize input array\n",
        "    initialize(h_input, input_size);\n",
        "\n",
        "    printf(\"Sample input: \");\n",
        "    print_array(h_input, 10);\n",
        "\n",
        "    // CPU scan\n",
        "    clock_t cpu_start = clock();\n",
        "    inclusive_scan_cpu(h_input, h_output_cpu, input_size);\n",
        "    clock_t cpu_end = clock();\n",
        "\n",
        "    printf(\"CPU scan completed in %f ms\\n\",\n",
        "           ((double)(cpu_end - cpu_start) / CLOCKS_PER_SEC) * 1000);\n",
        "\n",
        "    // Device memory allocation\n",
        "    int *d_input, *d_output;\n",
        "    gpuErrchk(cudaMalloc((void**)&d_input, byte_size));\n",
        "    gpuErrchk(cudaMalloc((void**)&d_output, byte_size));\n",
        "\n",
        "    // Copy input to device\n",
        "    gpuErrchk(cudaMemcpy(d_input, h_input, byte_size, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Launch GPU kernel\n",
        "    dim3 block(BLOCK_SIZE);\n",
        "    dim3 grid((input_size + block.x - 1) / block.x);\n",
        "\n",
        "    printf(\"Grid size: %d, Block size: %d\\n\", grid.x, block.x);\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    gpuErrchk(cudaEventCreate(&start));\n",
        "    gpuErrchk(cudaEventCreate(&stop));\n",
        "\n",
        "    gpuErrchk(cudaEventRecord(start));\n",
        "\n",
        "    // Launch kernel with shared memory\n",
        "    inclusive_scan_gpu<<<grid, block, BLOCK_SIZE * sizeof(int)>>>(d_input, d_output, input_size);\n",
        "\n",
        "    gpuErrchk(cudaEventRecord(stop));\n",
        "    gpuErrchk(cudaEventSynchronize(stop));\n",
        "\n",
        "    // Check for kernel launch errors\n",
        "    gpuErrchk(cudaGetLastError());\n",
        "\n",
        "    float gpu_time;\n",
        "    gpuErrchk(cudaEventElapsedTime(&gpu_time, start, stop));\n",
        "    printf(\"GPU scan completed in %f ms\\n\", gpu_time);\n",
        "\n",
        "    // Copy result back to host\n",
        "    gpuErrchk(cudaMemcpy(h_output_gpu, d_output, byte_size, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Compare results\n",
        "    printf(\"Comparing CPU and GPU results...\\n\");\n",
        "    compare_arrays(h_output_cpu, h_output_gpu, input_size);\n",
        "\n",
        "    printf(\"Sample CPU output: \");\n",
        "    print_array(h_output_cpu, 10);\n",
        "    printf(\"Sample GPU output: \");\n",
        "    print_array(h_output_gpu, 10);\n",
        "\n",
        "    // Cleanup\n",
        "    free(h_input);\n",
        "    free(h_output_cpu);\n",
        "    free(h_output_gpu);\n",
        "    gpuErrchk(cudaFree(d_input));\n",
        "    gpuErrchk(cudaFree(d_output));\n",
        "    gpuErrchk(cudaEventDestroy(start));\n",
        "    gpuErrchk(cudaEventDestroy(stop));\n",
        "    gpuErrchk(cudaDeviceReset());\n",
        "\n",
        "    printf(\"Execution completed successfully!\\n\");\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 one.cu -o one"
      ],
      "metadata": {
        "id": "gR1zoSEpU_bY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./one"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkEZswjJZ_bc",
        "outputId": "5aa3859f-e529-4049-fb8a-2f607abf4966"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scan algorithm execution started\n",
            "Input size: 1024 elements\n",
            "Sample input: Array: 1 1 1 1 1 1 1 1 1 1 \n",
            "CPU scan completed in 0.005000 ms\n",
            "Grid size: 2, Block size: 512\n",
            "GPU scan completed in 0.141312 ms\n",
            "Comparing CPU and GPU results...\n",
            "Arrays don't match at index 512: a[512]=513, b[512]=1\n",
            "Sample CPU output: Array: 1 2 3 4 5 6 7 8 9 10 \n",
            "Sample GPU output: Array: 1 2 3 4 5 6 7 8 9 10 \n",
            "Execution completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQmQE2GwbAWl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}