{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9K4Iq2g_K35",
        "outputId": "2ad41d44-33d7-44e1-e4ed-c213f4cc942d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 30 06:59:51 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8             13W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CUDA Device Properties**"
      ],
      "metadata": {
        "id": "3lbrtjkm_sR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile two.cu\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cstring>\n",
        "\n",
        "void query_device(){\n",
        "  int deviceCount = 0;\n",
        "  cudaError_t error = cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "  if (error != cudaSuccess) {\n",
        "    printf(\"CUDA Error: %s\\n\", cudaGetErrorString(error));\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  printf(\"Number of CUDA devices: %d\\n\", deviceCount);\n",
        "\n",
        "  if (deviceCount == 0){\n",
        "    printf(\"There are no available CUDA devices.\\n\");\n",
        "    printf(\"Make sure you have:\\n\");\n",
        "    printf(\"1. Enabled GPU runtime in Colab (Runtime -> Change runtime type -> GPU)\\n\");\n",
        "    printf(\"2. Restarted the runtime after enabling GPU\\n\");\n",
        "    return;\n",
        "  }\n",
        "\n",
        "  for (int devNo = 0; devNo < deviceCount; devNo++) {\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, devNo);\n",
        "\n",
        "    printf(\"\\nDevice %d : %s \\n\", devNo, deviceProp.name);\n",
        "    printf(\"Number of Multiprocessors : %d\\n\", deviceProp.multiProcessorCount);\n",
        "    printf(\"Compute Capability : %d.%d\\n\", deviceProp.major, deviceProp.minor);\n",
        "    printf(\"Total Global Memory : %.2f GB\\n\", deviceProp.totalGlobalMem / (1024.0 * 1024.0 * 1024.0));\n",
        "    printf(\"Max Threads per Block : %d\\n\", deviceProp.maxThreadsPerBlock);\n",
        "    printf(\"Warp Size : %d\\n\", deviceProp.warpSize);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  query_device();\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV-PMUpM_WJh",
        "outputId": "49e62896-166c-47ca-86de-5ec36feb399f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing two.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 two.cu -o two"
      ],
      "metadata": {
        "id": "OdtwxLwc_d52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk12F-iR_kLZ",
        "outputId": "63527d96-846a-4ce0-b3a6-8a5cf72933d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CUDA devices: 1\n",
            "\n",
            "Device 0 : Tesla T4 \n",
            "Number of Multiprocessors : 40\n",
            "Compute Capability : 7.5\n",
            "Total Global Memory : 14.74 GB\n",
            "Max Threads per Block : 1024\n",
            "Warp Size : 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sum Array Example**"
      ],
      "metadata": {
        "id": "8nxgPUHuAYv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile common.h\n",
        "//array comparison\n",
        "void compare_arrays(int *a, int *b, int size){\n",
        "  for(int i=0 ; i<size ; i++){\n",
        "    if(a[i] != b[i]){\n",
        "      printf(\"Arrays are different \\n\");\n",
        "      return;\n",
        "    }\n",
        "  }\n",
        "  printf(\"Arrays are same\");\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ktpuIXKAHAT",
        "outputId": "2a8c1089-3185-4612-cc9e-cca97a354912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing common.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile one.cu\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cstring>\n",
        "#include <time.h>\n",
        "#include \"common.h\"\n",
        "\n",
        "__global__ void sum_array(int *a, int *b, int *c, int size){\n",
        "  int gid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if(gid < size){\n",
        "    c[gid] = a[gid] + b[gid];\n",
        "  }\n",
        "}\n",
        "\n",
        "void sum_array_cpu(int *a, int *b, int *c, int size){\n",
        "  for(int i=0 ; i<size ; i++){\n",
        "    c[i] = a[i] + b[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  int size = 10000;\n",
        "  int block_size = 128;\n",
        "\n",
        "  int NO_BYTES = size * sizeof(int);\n",
        "\n",
        "  //host pointers\n",
        "  int *h_a, *h_b, *gpu_results, *h_c;\n",
        "\n",
        "  // allocate memory for host pointers\n",
        "  h_a = (int*)malloc(NO_BYTES);\n",
        "  h_b = (int*)malloc(NO_BYTES);\n",
        "  gpu_results = (int*)malloc(NO_BYTES);\n",
        "  h_c = (int*)malloc(NO_BYTES);\n",
        "\n",
        "  // initialize host pointers\n",
        "  time_t t;\n",
        "  srand((unsigned) time(&t));\n",
        "  for(int i=0 ; i<size ; i++){\n",
        "    h_a[i] = rand();\n",
        "    h_b[i] = rand();\n",
        "  }\n",
        "\n",
        "  memset(gpu_results, 0, NO_BYTES);\n",
        "  memset(h_c, 0, NO_BYTES);\n",
        "\n",
        "  sum_array_cpu(h_a, h_b, h_c, size);\n",
        "\n",
        "  //device pointers\n",
        "  int *d_a, *d_b, *d_results;\n",
        "  cudaMalloc((int **)&d_b, NO_BYTES);\n",
        "  cudaMalloc((int **)&d_a, NO_BYTES);\n",
        "  cudaMalloc((int **)&d_results, NO_BYTES);\n",
        "\n",
        "  //memory transfer from host to device\n",
        "  cudaMemcpy(d_a, h_a, NO_BYTES, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, h_b, NO_BYTES, cudaMemcpyHostToDevice);\n",
        "\n",
        "  //launching the grid\n",
        "  dim3 block(block_size);\n",
        "  dim3 grid((size + block.x - 1) / block.x);\n",
        "\n",
        "  //calling the kernel\n",
        "  sum_array<<<grid, block>>>(d_a, d_b, d_results, size);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  //memory transfer from device to host\n",
        "  cudaMemcpy(gpu_results, d_results, NO_BYTES, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  //array comparison\n",
        "  compare_arrays(gpu_results, h_c, size);\n",
        "\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_results);\n",
        "\n",
        "  free(gpu_results);\n",
        "  free(h_a);\n",
        "  free(h_b);\n",
        "  free(h_c);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MvTUFNf_lxd",
        "outputId": "2be8d3ca-7782-41e4-f04a-3eba32a3861b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting one.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 one.cu -o one"
      ],
      "metadata": {
        "id": "gJ7nhM6i__EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./one"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o43-t8BTAAsJ",
        "outputId": "44032747-a2f1-4d42-e0ab-15e94f565ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arrays are same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EnriF4XAAQxt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}