{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsyz0N9s2Bxw",
        "outputId": "38391031-99cc-4d30-b9fe-94f713e7d5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cmm_cuda.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile cmm_cuda.cu\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <climits>\n",
        "\n",
        "// Helper function to calculate diagonal-based index\n",
        "__device__ int getDiagonalIndex(int i, int j, int n) {\n",
        "    int diagonal = j - i;\n",
        "    int position = i - 1;\n",
        "\n",
        "    int offset = 0;\n",
        "    for (int d = 0; d < diagonal; d++) {\n",
        "        offset += (n - d);\n",
        "    }\n",
        "\n",
        "    return offset + position;\n",
        "}\n",
        "\n",
        "// Serial CPU implementation\n",
        "void chainMatrixMultiplication_Serial(int* dim, int** M, int** A, int n) {\n",
        "    for (int i = 1; i <= n; i++) {\n",
        "        M[i][i] = 0;\n",
        "    }\n",
        "\n",
        "    for (int len = 2; len <= n; len++) {\n",
        "        for (int i = 1; i <= n - len + 1; i++) {\n",
        "            int j = i + len - 1;\n",
        "            M[i][j] = INT_MAX;\n",
        "\n",
        "            for (int k = i; k <= j - 1; k++) {\n",
        "                int cost = M[i][k] + M[k + 1][j] + dim[i - 1] * dim[k] * dim[j];\n",
        "                if (cost < M[i][j]) {\n",
        "                    M[i][j] = cost;\n",
        "                    A[i][j] = k;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Basic CUDA kernel\n",
        "__global__ void CMM_CUDA_kernel(int* dev_dim, int* dev_m, int* dev_result, int n) {\n",
        "    int tid = threadIdx.x;\n",
        "    int matrix_size = n + 1;\n",
        "\n",
        "    if (tid < n) {\n",
        "        dev_m[tid * matrix_size + tid] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int len = 2; len <= n; len++) {\n",
        "        int diagonal_length = n - len + 1;\n",
        "\n",
        "        if (tid < diagonal_length) {\n",
        "            int i = tid + 1;\n",
        "            int j = i + len - 1;\n",
        "\n",
        "            int min_cost = INT_MAX;\n",
        "            for (int k = i; k <= j - 1; k++) {\n",
        "                int cost = dev_m[i * matrix_size + k] +\n",
        "                          dev_m[(k + 1) * matrix_size + j] +\n",
        "                          dev_dim[i - 1] * dev_dim[k] * dev_dim[j];\n",
        "                if (cost < min_cost) {\n",
        "                    min_cost = cost;\n",
        "                }\n",
        "            }\n",
        "            dev_m[i * matrix_size + j] = min_cost;\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        *dev_result = dev_m[1 * matrix_size + n];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Optimized CUDA kernel\n",
        "__global__ void CMM_CUDA_optimized_kernel(int* dev_dim, int* dev_m_diagonal, int* dev_result, int n) {\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    if (tid < n) {\n",
        "        int diagonal_idx = tid;\n",
        "        dev_m_diagonal[diagonal_idx] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int len = 2; len <= n; len++) {\n",
        "        int diagonal_length = n - len + 1;\n",
        "\n",
        "        if (tid < diagonal_length) {\n",
        "            int i = tid + 1;\n",
        "            int j = i + len - 1;\n",
        "\n",
        "            int min_cost = INT_MAX;\n",
        "            for (int k = i; k <= j - 1; k++) {\n",
        "                int left_diag_idx = getDiagonalIndex(i, k, n);\n",
        "                int right_diag_idx = getDiagonalIndex(k + 1, j, n);\n",
        "\n",
        "                int cost = dev_m_diagonal[left_diag_idx] +\n",
        "                          dev_m_diagonal[right_diag_idx] +\n",
        "                          dev_dim[i - 1] * dev_dim[k] * dev_dim[j];\n",
        "\n",
        "                if (cost < min_cost) {\n",
        "                    min_cost = cost;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            int current_diag_idx = getDiagonalIndex(i, j, n);\n",
        "            dev_m_diagonal[current_diag_idx] = min_cost;\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid == 0) {\n",
        "        int final_idx = getDiagonalIndex(1, n, n);\n",
        "        *dev_result = dev_m_diagonal[final_idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function to run single test\n",
        "void runSingleTest(int n, float* serial_time, float* cuda_time, float* optimized_time) {\n",
        "    // Initialize dimensions\n",
        "    int* dim = (int*)malloc((n + 1) * sizeof(int));\n",
        "    srand(42); // Fixed seed for consistent results\n",
        "    for (int i = 0; i <= n; i++) {\n",
        "        dim[i] = rand() % 100 + 1;\n",
        "    }\n",
        "\n",
        "    // Host memory allocation\n",
        "    int** M = (int**)malloc((n + 1) * sizeof(int*));\n",
        "    int** A = (int**)malloc((n + 1) * sizeof(int*));\n",
        "    for (int i = 0; i <= n; i++) {\n",
        "        M[i] = (int*)malloc((n + 1) * sizeof(int));\n",
        "        A[i] = (int*)malloc((n + 1) * sizeof(int));\n",
        "    }\n",
        "\n",
        "    // Device memory allocation\n",
        "    int* dev_dim;\n",
        "    int* dev_m;\n",
        "    int* dev_m_diagonal;\n",
        "    int* dev_result;\n",
        "\n",
        "    int matrix_size = (n + 1) * (n + 1);\n",
        "    int diagonal_size = (n * (n + 1)) / 2;\n",
        "\n",
        "    cudaMalloc(&dev_dim, (n + 1) * sizeof(int));\n",
        "    cudaMalloc(&dev_m, matrix_size * sizeof(int));\n",
        "    cudaMalloc(&dev_m_diagonal, diagonal_size * sizeof(int));\n",
        "    cudaMalloc(&dev_result, sizeof(int));\n",
        "\n",
        "    cudaMemcpy(dev_dim, dim, (n + 1) * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // CUDA Events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Timing serial version\n",
        "    cudaEventRecord(start);\n",
        "    chainMatrixMultiplication_Serial(dim, M, A, n);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(serial_time, start, stop);\n",
        "\n",
        "    // Timing basic CUDA version\n",
        "    cudaEventRecord(start);\n",
        "    CMM_CUDA_kernel<<<1, n>>>(dev_dim, dev_m, dev_result, n);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(cuda_time, start, stop);\n",
        "\n",
        "    // Timing optimized CUDA version\n",
        "    cudaEventRecord(start);\n",
        "    CMM_CUDA_optimized_kernel<<<1, n>>>(dev_dim, dev_m_diagonal, dev_result, n);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(optimized_time, start, stop);\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(dev_dim);\n",
        "    cudaFree(dev_m);\n",
        "    cudaFree(dev_m_diagonal);\n",
        "    cudaFree(dev_result);\n",
        "\n",
        "    for (int i = 0; i <= n; i++) {\n",
        "        free(M[i]);\n",
        "        free(A[i]);\n",
        "    }\n",
        "    free(M);\n",
        "    free(A);\n",
        "    free(dim);\n",
        "\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "\n",
        "    // Reset GPU state to avoid interference\n",
        "    cudaDeviceReset();\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Chain Matrix Multiplication Performance Comparison\\n\");\n",
        "    printf(\"================================================\\n\");\n",
        "    printf(\"| n    | Serial (ms) | CUDA (ms) | Optimized (ms) | CUDA Speedup | Opt Speedup |\\n\");\n",
        "    printf(\"|------|-------------|-----------|----------------|--------------|-------------|\\n\");\n",
        "\n",
        "    // Test range from 1016 to 1024\n",
        "    for (int n = 1016; n <= 1024; n++) {\n",
        "        float serial_time, cuda_time, optimized_time;\n",
        "\n",
        "        printf(\"Testing n = %d... \", n);\n",
        "        fflush(stdout);\n",
        "\n",
        "        runSingleTest(n, &serial_time, &cuda_time, &optimized_time);\n",
        "\n",
        "        float cuda_speedup = serial_time / cuda_time;\n",
        "        float opt_speedup = serial_time / optimized_time;\n",
        "\n",
        "        printf(\"Done\\n\");\n",
        "        printf(\"| %4d | %11.2f | %9.2f | %14.2f | %12.2fx | %11.2fx |\\n\",\n",
        "               n, serial_time, cuda_time, optimized_time, cuda_speedup, opt_speedup);\n",
        "    }\n",
        "\n",
        "    printf(\"\\nPerformance Analysis:\\n\");\n",
        "    printf(\"- Serial time grows as O(n³)\\n\");\n",
        "    printf(\"- CUDA basic should show consistent performance\\n\");\n",
        "    printf(\"- Optimized version performance depends on memory access patterns\\n\");\n",
        "    printf(\"- Each test uses fresh GPU state to avoid interference\\n\");\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "// Alternative: Multiple runs with averaging\n",
        "void runMultipleTests(int n, int num_runs, float* avg_serial, float* avg_cuda, float* avg_optimized) {\n",
        "    float total_serial = 0, total_cuda = 0, total_optimized = 0;\n",
        "\n",
        "    for (int run = 0; run < num_runs; run++) {\n",
        "        float serial_time, cuda_time, optimized_time;\n",
        "        runSingleTest(n, &serial_time, &cuda_time, &optimized_time);\n",
        "\n",
        "        total_serial += serial_time;\n",
        "        total_cuda += cuda_time;\n",
        "        total_optimized += optimized_time;\n",
        "    }\n",
        "\n",
        "    *avg_serial = total_serial / num_runs;\n",
        "    *avg_cuda = total_cuda / num_runs;\n",
        "    *avg_optimized = total_optimized / num_runs;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 cmm_cuda.cu -o cmm_cuda"
      ],
      "metadata": {
        "id": "BRdMIVcJ2zIe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./cmm_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2JtxhQo3DP9",
        "outputId": "7c90bb31-21af-4dcc-af20-27a0fdd3d08d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain Matrix Multiplication Performance Comparison\n",
            "================================================\n",
            "| n    | Serial (ms) | CUDA (ms) | Optimized (ms) | CUDA Speedup | Opt Speedup |\n",
            "|------|-------------|-----------|----------------|--------------|-------------|\n",
            "Testing n = 1016... Done\n",
            "| 1016 |     1442.25 |    350.61 |        1236.31 |         4.11x |        1.17x |\n",
            "Testing n = 1017... Done\n",
            "| 1017 |     2134.02 |    329.12 |        1235.78 |         6.48x |        1.73x |\n",
            "Testing n = 1018... Done\n",
            "| 1018 |     1471.09 |    175.22 |        1235.52 |         8.40x |        1.19x |\n",
            "Testing n = 1019... Done\n",
            "| 1019 |     1480.34 |    170.28 |        1239.59 |         8.69x |        1.19x |\n",
            "Testing n = 1020... Done\n",
            "| 1020 |     1535.18 |    168.26 |        1243.61 |         9.12x |        1.23x |\n",
            "Testing n = 1021... Done\n",
            "| 1021 |     1799.60 |    334.65 |        1247.89 |         5.38x |        1.44x |\n",
            "Testing n = 1022... Done\n",
            "| 1022 |     1455.19 |    261.08 |        1251.93 |         5.57x |        1.16x |\n",
            "Testing n = 1023... Done\n",
            "| 1023 |     1502.05 |    169.29 |        1256.10 |         8.87x |        1.20x |\n",
            "Testing n = 1024... Done\n",
            "| 1024 |     1887.73 |    316.29 |        1267.49 |         5.97x |        1.49x |\n",
            "\n",
            "Performance Analysis:\n",
            "- Serial time grows as O(n³)\n",
            "- CUDA basic should show consistent performance\n",
            "- Optimized version performance depends on memory access patterns\n",
            "- Each test uses fresh GPU state to avoid interference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HfJ9rlaR3GN0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}