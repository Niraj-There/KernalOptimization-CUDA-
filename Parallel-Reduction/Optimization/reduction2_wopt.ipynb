{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7osabfqhsY7D",
        "outputId": "2dc418e3-a1e8-4aae-c978-2edb804c83f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting three.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile three.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include<cuda_runtime.h>\n",
        "#include <chrono>\n",
        "#include <numeric>\n",
        "\n",
        "// REDUCTION 2 â€“ Sequence Addressing\n",
        "__global__ void reduce2(int *g_in_data, int *g_out_data){\n",
        "    extern __shared__ int sdata[];  // stored in the shared memory\n",
        "\n",
        "    // Each thread loading one element from global onto shared memory\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_in_data[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction method -- occurs in shared memory\n",
        "    for(unsigned int s = blockDim.x/2; s > 0; s >>= 1){\n",
        "        // check out the reverse loop above\n",
        "        if (tid < s){   // then, we check threadID to do our computation\n",
        "            sdata[tid] += sdata[tid + s];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (tid == 0){\n",
        "        g_out_data[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "// I hope to use this main file for all of the reduction files\n",
        "int main(){\n",
        "    int n = 1 << 22; // Increase to about 4M elements\n",
        "    size_t bytes = n * sizeof(int);\n",
        "\n",
        "    // Host/CPU arrays\n",
        "    int *host_input_data = new int[n];\n",
        "    int *host_output_data = new int[(n + 255) / 256]; // to have sufficient size for output array\n",
        "\n",
        "    // Device/GPU arrays\n",
        "    int *dev_input_data, *dev_output_data;\n",
        "\n",
        "    // Init data\n",
        "    srand(42); // Fixed seed\n",
        "    for (int i = 0; i < n; i++){\n",
        "        host_input_data[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    // Allocating memory on GPU for device arrays\n",
        "    cudaMalloc(&dev_input_data, bytes);\n",
        "    cudaMalloc(&dev_output_data, (n + 255) / 256 * sizeof(int));\n",
        "\n",
        "    // Copying our data onto the device (GPU)\n",
        "    cudaMemcpy(dev_input_data, host_input_data, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int blockSize = 256; // number of threads per block\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now(); // start timer\n",
        "\n",
        "    // Launch Kernel and Synchronize threads\n",
        "    int num_blocks = (n + blockSize - 1) / blockSize;\n",
        "    cudaError_t err;\n",
        "    reduce2<<<num_blocks, blockSize, blockSize * sizeof(int)>>>(dev_input_data, dev_output_data);\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(err) << std::endl;\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    auto stop = std::chrono::high_resolution_clock::now();\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(stop - start).count() / 1000.0; // duration in milliseconds with three decimal points\n",
        "\n",
        "    // Copying data back to the host (CPU)\n",
        "    cudaMemcpy(host_output_data, dev_output_data, (n + 255) / 256 * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Final reduction on the host\n",
        "    int finalResult = host_output_data[0];\n",
        "    for (int i = 1; i < (n + 255) / 256; ++i) {\n",
        "        finalResult += host_output_data[i];\n",
        "    }\n",
        "\n",
        "    // CPU Summation for verification\n",
        "    int cpuResult = std::accumulate(host_input_data, host_input_data + n, 0);\n",
        "    if (cpuResult == finalResult) {\n",
        "        std::cout << \"\\033[32m\"; // Set text color to green\n",
        "        std::cout << \"Verification successful: GPU result matches CPU result.\\n\";\n",
        "        std::cout << \"GPU Result: \" << finalResult << \", CPU Result: \" << cpuResult << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"\\033[31m\"; // Set text color to red\n",
        "        std::cout << \"Verification failed: GPU result (\" << finalResult << \") does not match CPU result (\" << cpuResult << \").\\n\";\n",
        "        std::cout << \"GPU Result: \" << finalResult << \", CPU Result: \" << cpuResult << std::endl;\n",
        "    }\n",
        "    std::cout << \"\\033[0m\"; // Reset text color to default\n",
        "\n",
        "    double bandwidth = (duration > 0) ? (bytes / duration / 1e6) : 0; // computed in GB/s, handling zero duration\n",
        "    std::cout << \"Reduced result: \" << finalResult << std::endl;\n",
        "    std::cout << \"Time elapsed: \" << duration << \" ms\" << std::endl;\n",
        "    std::cout << \"Effective bandwidth: \" << bandwidth << \" GB/s\" << std::endl;\n",
        "\n",
        "    // Freeing memory\n",
        "    cudaFree(dev_input_data);\n",
        "    cudaFree(dev_output_data);\n",
        "    delete[] host_input_data;\n",
        "    delete[] host_output_data;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 three.cu -o three"
      ],
      "metadata": {
        "id": "KyfFMxGUsgqR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./three"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq7m8DCvsmpf",
        "outputId": "525bbeb8-b7f8-4779-8b0b-4d2f8dddeb9e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.557 ms\n",
            "Effective bandwidth: 30.1207 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 three.cu -o three -O1 -lineinfo"
      ],
      "metadata": {
        "id": "hPS4FjA4so9E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./three"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI17LQjktMR0",
        "outputId": "2b23abc2-f348-4ef6-ee0b-38f0101ce5bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.528 ms\n",
            "Effective bandwidth: 31.775 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 three.cu -o three -O2 -lineinfo"
      ],
      "metadata": {
        "id": "yiOUgNpWtOlY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./three"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M49JbeUti3z",
        "outputId": "64bd3853-d1f3-4708-9319-6e76e3fb5b8b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.516 ms\n",
            "Effective bandwidth: 32.514 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 three.cu -o three -O3 -lineinfo"
      ],
      "metadata": {
        "id": "Y87oFm2Vtk5o"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./three"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbtNEDZct8QR",
        "outputId": "cbd79279-bf52-4940-c2ce-755b97d87282"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.522 ms\n",
            "Effective bandwidth: 32.1403 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "59HFAuEht-Fg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}