{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGX_tK1nofB-",
        "outputId": "2f1d2fdf-f617-4735-d736-532c7ce14dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing four.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile four.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include<cuda_runtime.h>\n",
        "#include <chrono>\n",
        "#include <numeric>\n",
        "\n",
        "// Adding this function to help with unrolling and adding the Template\n",
        "template <unsigned int blockSize>\n",
        "__device__ void warpReduce(volatile int* sdata, unsigned int tid){\n",
        "    if(blockSize >= 64) sdata[tid] += sdata[tid + 32];\n",
        "    if(blockSize >= 32) sdata[tid] += sdata[tid + 16];\n",
        "    if(blockSize >= 16) sdata[tid] += sdata[tid + 8];\n",
        "    if(blockSize >= 8) sdata[tid] += sdata[tid + 4];\n",
        "    if(blockSize >= 4) sdata[tid] += sdata[tid + 2];\n",
        "    if(blockSize >= 2) sdata[tid] += sdata[tid + 1];\n",
        "}\n",
        "\n",
        "// REDUCTION 6 â€“ Multiple Adds / Threads\n",
        "template <int blockSize>\n",
        "__global__ void reduce6(int *g_in_data, int *g_out_data, unsigned int n){\n",
        "    extern __shared__ int sdata[];  // stored in the shared memory\n",
        "\n",
        "    // Each thread loading one element from global onto shared memory\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x*(blockSize*2) + tid;\n",
        "    unsigned int gridSize = blockDim.x * 2 * gridDim.x;\n",
        "    sdata[tid] = 0;\n",
        "\n",
        "    while(i < n) {\n",
        "      sdata[tid] += g_in_data[i] + g_in_data[i + blockSize];\n",
        "      i += gridSize;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Perform reductions in steps, reducing thread synchronization\n",
        "    if (blockSize >= 512) {\n",
        "        if (tid < 256) { sdata[tid] += sdata[tid + 256]; } __syncthreads();\n",
        "    }\n",
        "    if (blockSize >= 256) {\n",
        "        if (tid < 128) { sdata[tid] += sdata[tid + 128]; } __syncthreads();\n",
        "    }\n",
        "    if (blockSize >= 128) {\n",
        "        if (tid < 64) { sdata[tid] += sdata[tid + 64]; } __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid < 32) warpReduce<blockSize>(sdata, tid);\n",
        "\n",
        "    if (tid == 0){\n",
        "        g_out_data[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "// I hope to use this main file for all of the reduction files\n",
        "int main(){\n",
        "    int n = 1<<22; // Increase to about 4M elements\n",
        "    size_t bytes = n * sizeof(int);\n",
        "\n",
        "    // Host/CPU arrays\n",
        "    int *host_input_data = new int[n];\n",
        "    int *host_output_data = new int[(n + 255) / 256]; // to have sufficient size for output array\n",
        "\n",
        "    // Device/GPU arrays\n",
        "    int *dev_input_data, *dev_output_data;\n",
        "\n",
        "    // Init data\n",
        "    srand(42); // Fixed seed\n",
        "    for (int i = 0; i < n; i++){\n",
        "        host_input_data[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    // Allocating memory on GPU for device arrays\n",
        "    cudaMalloc(&dev_input_data, bytes);\n",
        "    cudaMalloc(&dev_output_data, (n + 255) / 256 * sizeof(int));\n",
        "\n",
        "    // Copying our data onto the device (GPU)\n",
        "    cudaMemcpy(dev_input_data, host_input_data, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int blockSize = 256; // number of threads per block\n",
        "    int num_blocks = (n + (2 * blockSize) - 1) / (2 * blockSize);   // Modifying this to account for the fact that 1 thread accesses 2 elements\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now(); // start timer\n",
        "\n",
        "    // Needed for Complete unrolling\n",
        "    // Launch Kernel and Synchronize threads\n",
        "    switch (blockSize) {\n",
        "        case 512:\n",
        "            reduce6<512><<<num_blocks, 512, 512 * sizeof(int)>>>(dev_input_data, dev_output_data, n);\n",
        "            break;\n",
        "        case 256:\n",
        "            reduce6<256><<<num_blocks, 256, 256 * sizeof(int)>>>(dev_input_data, dev_output_data, n);\n",
        "            break;\n",
        "        case 128:\n",
        "            reduce6<128><<<num_blocks, 128, 128 * sizeof(int)>>>(dev_input_data, dev_output_data, n);\n",
        "            break;\n",
        "    }\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    auto stop = std::chrono::high_resolution_clock::now();\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(stop - start).count() / 1000.0; // duration in milliseconds with three decimal points\n",
        "\n",
        "    // Copying data back to the host (CPU)\n",
        "    cudaMemcpy(host_output_data, dev_output_data, (n + 255) / 256 * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Final reduction on the host\n",
        "    int finalResult = host_output_data[0];\n",
        "    for (int i = 1; i < (n + 255) / 256; ++i) {\n",
        "        finalResult += host_output_data[i];\n",
        "    }\n",
        "\n",
        "    // CPU Summation for verification\n",
        "    int cpuResult = std::accumulate(host_input_data, host_input_data + n, 0);\n",
        "    if (cpuResult == finalResult) {\n",
        "        std::cout << \"\\033[32m\"; // Set text color to green\n",
        "        std::cout << \"Verification successful: GPU result matches CPU result.\\n\";\n",
        "        std::cout << \"GPU Result: \" << finalResult << \", CPU Result: \" << cpuResult << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"\\033[31m\"; // Set text color to red\n",
        "        std::cout << \"Verification failed: GPU result (\" << finalResult << \") does not match CPU result (\" << cpuResult << \").\\n\";\n",
        "        std::cout << \"GPU Result: \" << finalResult << \", CPU Result: \" << cpuResult << std::endl;\n",
        "    }\n",
        "    std::cout << \"\\033[0m\"; // Reset text color to default\n",
        "\n",
        "    double bandwidth = (duration > 0) ? (bytes / duration / 1e6) : 0; // computed in GB/s, handling zero duration\n",
        "    std::cout << \"Reduced result: \" << finalResult << std::endl;\n",
        "    std::cout << \"Time elapsed: \" << duration << \" ms\" << std::endl;\n",
        "    std::cout << \"Effective bandwidth: \" << bandwidth << \" GB/s\" << std::endl;\n",
        "\n",
        "    // Freeing memory\n",
        "    cudaFree(dev_input_data);\n",
        "    cudaFree(dev_output_data);\n",
        "    delete[] host_input_data;\n",
        "    delete[] host_output_data;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 one.cu -o one"
      ],
      "metadata": {
        "id": "L2WPdXpEon1L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./one"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpSXXQDmotVR",
        "outputId": "ead82358-169d-4410-df17-077a5378a3cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.284 ms\n",
            "Effective bandwidth: 59.0747 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 two.cu -o two -O1 -lineinfo"
      ],
      "metadata": {
        "id": "NRpBoB65L1Ce"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEWGrRe8MYZ1",
        "outputId": "4b64829f-3e7a-4959-f5cf-eaa71b8b1c69"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.326 ms\n",
            "Effective bandwidth: 51.4639 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 three.cu -o three -O2 -lineinfo"
      ],
      "metadata": {
        "id": "Tty0r8egMaII"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./three"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36BUkP_FMhQo",
        "outputId": "35a3c28a-d7e2-466c-f708-464a9c3dfd24"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.284 ms\n",
            "Effective bandwidth: 59.0747 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 four.cu -o four -O3 -lineinfo"
      ],
      "metadata": {
        "id": "1WCxVc_lMixY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./four"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxVjC6EFMn0l",
        "outputId": "26c30212-08dd-4975-d9df-d723aec12120"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.862 ms\n",
            "Effective bandwidth: 19.4631 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! set -x \\\n",
        "&& cd $(mktemp -d) \\\n",
        "&& wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run \\\n",
        "&& sudo sh cuda_12.1.0_530.30.02_linux.run --silent --toolkit \\\n",
        "&& rm cuda_12.1.0_530.30.02_linux.run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KddPriILMo_s",
        "outputId": "c16463ec-bf7d-4e68-8d98-da0663b1293a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++ mktemp -d\n",
            "+ cd /tmp/tmp.uhY8BH96A1\n",
            "+ wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run\n",
            "--2025-06-12 17:32:04--  https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.43.51.18, 23.43.51.10, 23.43.51.12\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.43.51.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4245586997 (4.0G) [application/octet-stream]\n",
            "Saving to: â€˜cuda_12.1.0_530.30.02_linux.runâ€™\n",
            "\n",
            "cuda_12.1.0_530.30. 100%[===================>]   3.95G   117MB/s    in 42s     \n",
            "\n",
            "2025-06-12 17:32:47 (95.6 MB/s) - â€˜cuda_12.1.0_530.30.02_linux.runâ€™ saved [4245586997/4245586997]\n",
            "\n",
            "+ sudo sh cuda_12.1.0_530.30.02_linux.run --silent --toolkit\n",
            "+ rm cuda_12.1.0_530.30.02_linux.run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] = os.environ['PATH'] + ':/usr/local/cuda/bin/'"
      ],
      "metadata": {
        "id": "ooA6GlniMuUL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu ./one -o reduction_report_no"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14xG0ijlNzdW",
        "outputId": "b1e256b4-7dde-4a5a-9d8a-3a377233b59a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 3773 (/content/one)\n",
            "==PROF== Profiling \"reduce6\" - 0: 0%....50%....100% - 9 passes\n",
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 505.11 ms\n",
            "Effective bandwidth: 0.033215 GB/s\n",
            "==PROF== Disconnected from process 3773\n",
            "[3773] one@127.0.0.1\n",
            "  void reduce6<256>(int *, int *, unsigned int) (8192, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.93\n",
            "    SM Frequency                    Mhz       584.70\n",
            "    Elapsed Cycles                cycle       78,120\n",
            "    Memory Throughput                 %        57.17\n",
            "    DRAM Throughput                   %        52.05\n",
            "    Duration                         us       133.60\n",
            "    L1/TEX Cache Throughput           %        61.94\n",
            "    L2 Cache Throughput               %        14.63\n",
            "    SM Active Cycles              cycle    75,743.73\n",
            "    Compute (SM) Throughput           %        57.17\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  8,192\n",
            "    Registers Per Thread             register/thread              16\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block      Kbyte/block            1.02\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread       2,097,152\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                               51.20\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           16\n",
            "    Block Limit Shared Mem                block           32\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        72.56\n",
            "    Achieved Active Warps Per SM           warp        23.22\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 27.44%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (72.6%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle      342,686\n",
            "    Total DRAM Elapsed Cycles        cycle    5,267,456\n",
            "    Average L1 Active Cycles         cycle    75,743.73\n",
            "    Total L1 Elapsed Cycles          cycle    3,095,120\n",
            "    Average L2 Active Cycles         cycle   102,331.62\n",
            "    Total L2 Elapsed Cycles          cycle    3,653,024\n",
            "    Average SM Active Cycles         cycle    75,743.73\n",
            "    Total SM Elapsed Cycles          cycle    3,095,120\n",
            "    Average SMSP Active Cycles       cycle    72,765.76\n",
            "    Total SMSP Elapsed Cycles        cycle   12,380,480\n",
            "    -------------------------- ----------- ------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu ./two -o reduction_report_o1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap-EtxmLN8rj",
        "outputId": "c7fd633f-cee7-4c62-8454-2f3b4c7ea03d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 3873 (/content/two)\n",
            "==PROF== Profiling \"reduce6\" - 0: 0%....50%....100% - 9 passes\n",
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 311.836 ms\n",
            "Effective bandwidth: 0.0538014 GB/s\n",
            "==PROF== Disconnected from process 3873\n",
            "[3873] two@127.0.0.1\n",
            "  void reduce6<256>(int *, int *, unsigned int) (8192, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.95\n",
            "    SM Frequency                    Mhz       584.72\n",
            "    Elapsed Cycles                cycle       78,312\n",
            "    Memory Throughput                 %        57.00\n",
            "    DRAM Throughput                   %        51.59\n",
            "    Duration                         us       133.92\n",
            "    L1/TEX Cache Throughput           %        61.78\n",
            "    L2 Cache Throughput               %        14.59\n",
            "    SM Active Cycles              cycle    75,484.73\n",
            "    Compute (SM) Throughput           %        57.00\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  8,192\n",
            "    Registers Per Thread             register/thread              16\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block      Kbyte/block            1.02\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread       2,097,152\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                               51.20\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           16\n",
            "    Block Limit Shared Mem                block           32\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        73.27\n",
            "    Achieved Active Warps Per SM           warp        23.45\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 26.73%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.3%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle      341,782\n",
            "    Total DRAM Elapsed Cycles        cycle    5,300,224\n",
            "    Average L1 Active Cycles         cycle    75,484.73\n",
            "    Total L1 Elapsed Cycles          cycle    3,104,080\n",
            "    Average L2 Active Cycles         cycle   105,045.19\n",
            "    Total L2 Elapsed Cycles          cycle    3,662,112\n",
            "    Average SM Active Cycles         cycle    75,484.73\n",
            "    Total SM Elapsed Cycles          cycle    3,104,080\n",
            "    Average SMSP Active Cycles       cycle    72,847.77\n",
            "    Total SMSP Elapsed Cycles        cycle   12,416,320\n",
            "    -------------------------- ----------- ------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu ./three -o reduction_report_o2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj9ZmLzON_o7",
        "outputId": "4529f467-ddc0-4a48-cae4-8f3615a2ff42"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 3967 (/content/three)\n",
            "==PROF== Profiling \"reduce6\" - 0: 0%....50%....100% - 9 passes\n",
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 308.418 ms\n",
            "Effective bandwidth: 0.0543977 GB/s\n",
            "==PROF== Disconnected from process 3967\n",
            "[3967] three@127.0.0.1\n",
            "  void reduce6<256>(int *, int *, unsigned int) (8192, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.92\n",
            "    SM Frequency                    Mhz       584.88\n",
            "    Elapsed Cycles                cycle       78,333\n",
            "    Memory Throughput                 %        56.89\n",
            "    DRAM Throughput                   %        51.67\n",
            "    Duration                         us       133.92\n",
            "    L1/TEX Cache Throughput           %        61.65\n",
            "    L2 Cache Throughput               %        14.59\n",
            "    SM Active Cycles              cycle    75,644.07\n",
            "    Compute (SM) Throughput           %        56.89\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  8,192\n",
            "    Registers Per Thread             register/thread              16\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block      Kbyte/block            1.02\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread       2,097,152\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                               51.20\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           16\n",
            "    Block Limit Shared Mem                block           32\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        73.22\n",
            "    Achieved Active Warps Per SM           warp        23.43\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 26.78%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.2%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle      340,759\n",
            "    Total DRAM Elapsed Cycles        cycle    5,275,648\n",
            "    Average L1 Active Cycles         cycle    75,644.07\n",
            "    Total L1 Elapsed Cycles          cycle    3,110,496\n",
            "    Average L2 Active Cycles         cycle   104,420.41\n",
            "    Total L2 Elapsed Cycles          cycle    3,663,104\n",
            "    Average SM Active Cycles         cycle    75,644.07\n",
            "    Total SM Elapsed Cycles          cycle    3,110,496\n",
            "    Average SMSP Active Cycles       cycle    73,023.11\n",
            "    Total SMSP Elapsed Cycles        cycle   12,441,984\n",
            "    -------------------------- ----------- ------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu ./four -o reduction_report_o3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ-fiP7EOCRc",
        "outputId": "2cde2850-312d-43d3-c6d9-f982e6808b2b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 4061 (/content/four)\n",
            "==PROF== Profiling \"reduce6\" - 0: 0%....50%....100% - 9 passes\n",
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 308.84 ms\n",
            "Effective bandwidth: 0.0543233 GB/s\n",
            "==PROF== Disconnected from process 4061\n",
            "[4061] four@127.0.0.1\n",
            "  void reduce6<256>(int *, int *, unsigned int) (8192, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.95\n",
            "    SM Frequency                    Mhz       584.81\n",
            "    Elapsed Cycles                cycle       78,247\n",
            "    Memory Throughput                 %        57.02\n",
            "    DRAM Throughput                   %        51.56\n",
            "    Duration                         us       133.79\n",
            "    L1/TEX Cache Throughput           %        61.79\n",
            "    L2 Cache Throughput               %        14.61\n",
            "    SM Active Cycles              cycle    75,740.05\n",
            "    Compute (SM) Throughput           %        57.02\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  8,192\n",
            "    Registers Per Thread             register/thread              16\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block      Kbyte/block            1.02\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread       2,097,152\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                               51.20\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           16\n",
            "    Block Limit Shared Mem                block           32\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        72.97\n",
            "    Achieved Active Warps Per SM           warp        23.35\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 27.03%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (73.0%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   341,498.50\n",
            "    Total DRAM Elapsed Cycles        cycle    5,298,176\n",
            "    Average L1 Active Cycles         cycle    75,740.05\n",
            "    Total L1 Elapsed Cycles          cycle    3,103,128\n",
            "    Average L2 Active Cycles         cycle   102,546.59\n",
            "    Total L2 Elapsed Cycles          cycle    3,659,072\n",
            "    Average SM Active Cycles         cycle    75,740.05\n",
            "    Total SM Elapsed Cycles          cycle    3,103,128\n",
            "    Average SMSP Active Cycles       cycle    72,896.38\n",
            "    Total SMSP Elapsed Cycles        cycle   12,412,512\n",
            "    -------------------------- ----------- ------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./one"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nifCWQ07OFJQ",
        "outputId": "45c41047-d8b6-4d85-bc2b-8a80f6ab4789"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4186== NVPROF is profiling process 4186, command: ./one\n",
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 1.509 ms\n",
            "Effective bandwidth: 11.1181 GB/s\n",
            "==4186== Profiling application: ./one\n",
            "==4186== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   95.82%  3.5014ms         1  3.5014ms  3.5014ms  3.5014ms  [CUDA memcpy HtoD]\n",
            "                    3.97%  145.21us         1  145.21us  145.21us  145.21us  void reduce6<int=256>(int*, int*, unsigned int)\n",
            "                    0.20%  7.4230us         1  7.4230us  7.4230us  7.4230us  [CUDA memcpy DtoH]\n",
            "      API calls:   94.22%  103.58ms         2  51.789ms  78.952us  103.50ms  cudaMalloc\n",
            "                    3.48%  3.8295ms         2  1.9147ms  85.689us  3.7438ms  cudaMemcpy\n",
            "                    1.23%  1.3497ms         1  1.3497ms  1.3497ms  1.3497ms  cudaLaunchKernel\n",
            "                    0.78%  861.86us         2  430.93us  140.88us  720.98us  cudaFree\n",
            "                    0.13%  145.72us         1  145.72us  145.72us  145.72us  cudaDeviceSynchronize\n",
            "                    0.13%  144.99us       114  1.2710us     139ns  60.363us  cuDeviceGetAttribute\n",
            "                    0.01%  12.076us         1  12.076us  12.076us  12.076us  cuDeviceGetName\n",
            "                    0.01%  6.3440us         1  6.3440us  6.3440us  6.3440us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2240us         3     741ns     216ns  1.7140us  cuDeviceGetCount\n",
            "                    0.00%  1.1510us         2     575ns     202ns     949ns  cuDeviceGet\n",
            "                    0.00%     731ns         1     731ns     731ns     731ns  cuModuleGetLoadingMode\n",
            "                    0.00%     445ns         1     445ns     445ns     445ns  cuDeviceTotalMem\n",
            "                    0.00%     269ns         1     269ns     269ns     269ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof --print-gpu-trace ./one"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V2Fz0s8OLgD",
        "outputId": "b22eba42-4a60-44b3-96f2-847093940de6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4369== NVPROF is profiling process 4369, command: ./one\n",
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.399 ms\n",
            "Effective bandwidth: 42.0482 GB/s\n",
            "==4369== Profiling application: ./one\n",
            "==4369== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name\n",
            "236.86ms  18.290ms                    -               -         -         -         -  16.000MB  874.79MB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "255.33ms  145.12us           (8192 1 1)       (256 1 1)        16        0B  1.0000KB         -           -           -           -     Tesla T4 (0)         1         7  void reduce6<int=256>(int*, int*, unsigned int) [128]\n",
            "255.50ms  7.3920us                    -               -         -         -         -  64.000KB  8.2569GB/s      Device    Pageable     Tesla T4 (0)         1         7  [CUDA memcpy DtoH]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n",
            "SrcMemType: The type of source memory accessed by memory operation/copy\n",
            "DstMemType: The type of destination memory accessed by memory operation/copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siUW1IAmOVcm",
        "outputId": "f3978193-87b4-4452-d5e1-3d7b471e67c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4470== NVPROF is profiling process 4470, command: ./two\n",
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.315 ms\n",
            "Effective bandwidth: 53.261 GB/s\n",
            "==4470== Profiling application: ./two\n",
            "==4470== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   95.90%  3.5766ms         1  3.5766ms  3.5766ms  3.5766ms  [CUDA memcpy HtoD]\n",
            "                    3.90%  145.50us         1  145.50us  145.50us  145.50us  void reduce6<int=256>(int*, int*, unsigned int)\n",
            "                    0.20%  7.4240us         1  7.4240us  7.4240us  7.4240us  [CUDA memcpy DtoH]\n",
            "      API calls:   95.25%  103.75ms         2  51.873ms  76.900us  103.67ms  cudaMalloc\n",
            "                    3.53%  3.8451ms         2  1.9225ms  78.365us  3.7667ms  cudaMemcpy\n",
            "                    0.79%  860.35us         2  430.18us  142.95us  717.40us  cudaFree\n",
            "                    0.15%  162.82us         1  162.82us  162.82us  162.82us  cudaLaunchKernel\n",
            "                    0.14%  147.23us         1  147.23us  147.23us  147.23us  cudaDeviceSynchronize\n",
            "                    0.12%  134.57us       114  1.1800us     139ns  53.338us  cuDeviceGetAttribute\n",
            "                    0.01%  12.532us         1  12.532us  12.532us  12.532us  cuDeviceGetName\n",
            "                    0.01%  6.4050us         1  6.4050us  6.4050us  6.4050us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.5900us         3     863ns     315ns  1.7890us  cuDeviceGetCount\n",
            "                    0.00%  1.0570us         2     528ns     179ns     878ns  cuDeviceGet\n",
            "                    0.00%     604ns         1     604ns     604ns     604ns  cuModuleGetLoadingMode\n",
            "                    0.00%     410ns         1     410ns     410ns     410ns  cuDeviceTotalMem\n",
            "                    0.00%     266ns         1     266ns     266ns     266ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./three"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNcADhlKOayX",
        "outputId": "60d24d53-4854-41bf-d6f4-fe5fb2daa9bc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4507== NVPROF is profiling process 4507, command: ./three\n",
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.314 ms\n",
            "Effective bandwidth: 53.4306 GB/s\n",
            "==4507== Profiling application: ./three\n",
            "==4507== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   95.98%  3.6384ms         1  3.6384ms  3.6384ms  3.6384ms  [CUDA memcpy HtoD]\n",
            "                    3.82%  144.89us         1  144.89us  144.89us  144.89us  void reduce6<int=256>(int*, int*, unsigned int)\n",
            "                    0.20%  7.3920us         1  7.3920us  7.3920us  7.3920us  [CUDA memcpy DtoH]\n",
            "      API calls:   95.53%  111.27ms         2  55.635ms  80.020us  111.19ms  cudaMalloc\n",
            "                    3.33%  3.8814ms         2  1.9407ms  73.568us  3.8078ms  cudaMemcpy\n",
            "                    0.74%  858.86us         2  429.43us  148.62us  710.24us  cudaFree\n",
            "                    0.14%  162.41us         1  162.41us  162.41us  162.41us  cudaLaunchKernel\n",
            "                    0.13%  147.17us         1  147.17us  147.17us  147.17us  cudaDeviceSynchronize\n",
            "                    0.12%  138.91us       114  1.2180us     138ns  53.812us  cuDeviceGetAttribute\n",
            "                    0.01%  12.031us         1  12.031us  12.031us  12.031us  cuDeviceGetName\n",
            "                    0.00%  5.5050us         1  5.5050us  5.5050us  5.5050us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.7060us         2  1.3530us     285ns  2.4210us  cuDeviceGet\n",
            "                    0.00%  1.8030us         3     601ns     225ns  1.0900us  cuDeviceGetCount\n",
            "                    0.00%     500ns         1     500ns     500ns     500ns  cuDeviceTotalMem\n",
            "                    0.00%     470ns         1     470ns     470ns     470ns  cuModuleGetLoadingMode\n",
            "                    0.00%     215ns         1     215ns     215ns     215ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof ./four"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzC-_zQJOcOT",
        "outputId": "0ca1ba5f-d4e9-4aef-f527-7b2241607055"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==4544== NVPROF is profiling process 4544, command: ./four\n",
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.301 ms\n",
            "Effective bandwidth: 55.7383 GB/s\n",
            "==4544== Profiling application: ./four\n",
            "==4544== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   95.78%  3.4625ms         1  3.4625ms  3.4625ms  3.4625ms  [CUDA memcpy HtoD]\n",
            "                    4.02%  145.24us         1  145.24us  145.24us  145.24us  void reduce6<int=256>(int*, int*, unsigned int)\n",
            "                    0.20%  7.3910us         1  7.3910us  7.3910us  7.3910us  [CUDA memcpy DtoH]\n",
            "      API calls:   95.36%  103.38ms         2  51.692ms  110.37us  103.27ms  cudaMalloc\n",
            "                    3.44%  3.7266ms         2  1.8633ms  86.762us  3.6398ms  cudaMemcpy\n",
            "                    0.78%  850.89us         2  425.45us  136.91us  713.98us  cudaFree\n",
            "                    0.14%  148.41us         1  148.41us  148.41us  148.41us  cudaLaunchKernel\n",
            "                    0.14%  147.81us         1  147.81us  147.81us  147.81us  cudaDeviceSynchronize\n",
            "                    0.13%  137.32us       114  1.2040us     142ns  55.028us  cuDeviceGetAttribute\n",
            "                    0.01%  11.425us         1  11.425us  11.425us  11.425us  cuDeviceGetName\n",
            "                    0.01%  7.5560us         1  7.5560us  7.5560us  7.5560us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.9460us         3     648ns     232ns  1.3520us  cuDeviceGetCount\n",
            "                    0.00%  1.4800us         2     740ns     262ns  1.2180us  cuDeviceGet\n",
            "                    0.00%     832ns         1     832ns     832ns     832ns  cuModuleGetLoadingMode\n",
            "                    0.00%     575ns         1     575ns     575ns     575ns  cuDeviceTotalMem\n",
            "                    0.00%     222ns         1     222ns     222ns     222ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsqvCPfAOdlJ",
        "outputId": "27e8d17d-e6ea-4c60-c3eb-2cf4ac8b2bc1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA Nsight Systems version 2023.1.2.43-32377213v0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys profile ./one"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSyG6HkrOgIs",
        "outputId": "2a6badeb-7b44-453b-c528-5b943994e1a1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.3 ms\n",
            "Effective bandwidth: 55.9241 GB/s\n",
            "Generating '/tmp/nsys-report-dbb9.qdstrm'\n",
            "[1/1] [========================100%] report1.nsys-rep\n",
            "Generated:\n",
            "    /content/report1.nsys-rep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys stats report1.nsys-rep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMW3THzoOkHu",
        "outputId": "fae08e9f-f303-4f1b-a2ca-54ce5996ec5f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating SQLite file report1.sqlite from report1.nsys-rep\n",
            "\rExporting 1563 events: [1%                                                     ]\rExporting 1563 events: [2%                                                     ]\rExporting 1563 events: [3%                                                     ]\rExporting 1563 events: [4%                                                     ]\rExporting 1563 events: [5%                                                     ]\rExporting 1563 events: [=6%                                                    ]\rExporting 1563 events: [=7%                                                    ]\rExporting 1563 events: [==8%                                                   ]\rExporting 1563 events: [==9%                                                   ]\rExporting 1563 events: [==10%                                                  ]\rExporting 1563 events: [===11%                                                 ]\rExporting 1563 events: [===12%                                                 ]\rExporting 1563 events: [====13%                                                ]\rExporting 1563 events: [====14%                                                ]\rExporting 1563 events: [=====15%                                               ]\rExporting 1563 events: [=====16%                                               ]\rExporting 1563 events: [======17%                                              ]\rExporting 1563 events: [======18%                                              ]\rExporting 1563 events: [=======19%                                             ]\rExporting 1563 events: [========20%                                            ]\rExporting 1563 events: [========21%                                            ]\rExporting 1563 events: [=========22%                                           ]\rExporting 1563 events: [=========23%                                           ]\rExporting 1563 events: [==========24%                                          ]\rExporting 1563 events: [==========25%                                          ]\rExporting 1563 events: [===========26%                                         ]\rExporting 1563 events: [===========27%                                         ]\rExporting 1563 events: [============28%                                        ]\rExporting 1563 events: [============29%                                        ]\rExporting 1563 events: [=============30%                                       ]\rExporting 1563 events: [==============31%                                      ]\rExporting 1563 events: [==============32%                                      ]\rExporting 1563 events: [===============33%                                     ]\rExporting 1563 events: [===============34%                                     ]\rExporting 1563 events: [================35%                                    ]\rExporting 1563 events: [================36%                                    ]\rExporting 1563 events: [=================37%                                   ]\rExporting 1563 events: [=================38%                                   ]\rExporting 1563 events: [==================39%                                  ]\rExporting 1563 events: [===================40%                                 ]\rExporting 1563 events: [===================41%                                 ]\rExporting 1563 events: [====================42%                                ]\rExporting 1563 events: [====================43%                                ]\rExporting 1563 events: [=====================44%                               ]\rExporting 1563 events: [=====================45%                               ]\rExporting 1563 events: [======================46%                              ]\rExporting 1563 events: [======================47%                              ]\rExporting 1563 events: [=======================48%                             ]\rExporting 1563 events: [=======================49%                             ]\rExporting 1563 events: [========================50%                            ]\rExporting 1563 events: [=========================51%                           ]\rExporting 1563 events: [=========================52%                           ]\rExporting 1563 events: [==========================53%                          ]\rExporting 1563 events: [==========================54%                          ]\rExporting 1563 events: [===========================55%                         ]\rExporting 1563 events: [===========================56%                         ]\rExporting 1563 events: [============================57%                        ]\rExporting 1563 events: [============================58%                        ]\rExporting 1563 events: [=============================59%                       ]\rExporting 1563 events: [==============================60%                      ]\rExporting 1563 events: [==============================61%                      ]\rExporting 1563 events: [===============================62%                     ]\rExporting 1563 events: [===============================63%                     ]\rExporting 1563 events: [================================64%                    ]\rExporting 1563 events: [================================65%                    ]\rExporting 1563 events: [=================================66%                   ]\rExporting 1563 events: [=================================67%                   ]\rExporting 1563 events: [==================================68%                  ]\rExporting 1563 events: [==================================69%                  ]\rExporting 1563 events: [===================================70%                 ]\rExporting 1563 events: [====================================71%                ]\rExporting 1563 events: [====================================72%                ]\rExporting 1563 events: [=====================================73%               ]\rExporting 1563 events: [=====================================74%               ]\rExporting 1563 events: [======================================75%              ]\rExporting 1563 events: [======================================76%              ]\rExporting 1563 events: [=======================================77%             ]\rExporting 1563 events: [=======================================78%             ]\rExporting 1563 events: [========================================79%            ]\rExporting 1563 events: [=========================================80%           ]\rExporting 1563 events: [=========================================81%           ]\rExporting 1563 events: [==========================================82%          ]\rExporting 1563 events: [==========================================83%          ]\rExporting 1563 events: [===========================================84%         ]\rExporting 1563 events: [===========================================85%         ]\rExporting 1563 events: [============================================86%        ]\rExporting 1563 events: [============================================87%        ]\rExporting 1563 events: [=============================================88%       ]\rExporting 1563 events: [=============================================89%       ]\rExporting 1563 events: [==============================================90%      ]\rExporting 1563 events: [===============================================91%     ]\rExporting 1563 events: [===============================================92%     ]\rExporting 1563 events: [================================================93%    ]\rExporting 1563 events: [================================================94%    ]\rExporting 1563 events: [=================================================95%   ]\rExporting 1563 events: [=================================================96%   ]\rExporting 1563 events: [==================================================97%  ]\rExporting 1563 events: [==================================================98%  ]\rExporting 1563 events: [===================================================99% ]\rExporting 1563 events: [===================================================100%]\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/nvtx_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/osrt_sum.py]... \n",
            "\n",
            " ** OS Runtime Summary (osrt_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)     Min (ns)    Max (ns)     StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  -------------  -------------  ---------  -----------  -------------  ----------------------\n",
            "     47.2      435,351,451          2  217,675,725.5  217,675,725.5  2,136,355  433,215,096  304,818,701.0  sem_wait              \n",
            "     44.9      414,100,651         13   31,853,896.2    2,696,400.0      1,521  313,742,288   85,732,312.4  poll                  \n",
            "      7.4       68,354,182        536      127,526.5       14,297.0        428   18,565,648    1,041,345.3  ioctl                 \n",
            "      0.2        1,927,301         31       62,171.0       14,252.0     10,443    1,171,880      206,644.7  mmap64                \n",
            "      0.1          486,046         10       48,604.6       51,401.5     13,600       81,653       20,324.6  sem_timedwait         \n",
            "      0.0          426,995         49        8,714.2        7,683.0      3,987       21,147        3,502.6  open64                \n",
            "      0.0          295,334         47        6,283.7        4,728.0      1,704       31,013        5,889.1  fopen                 \n",
            "      0.0          276,597          4       69,149.3       56,886.5     49,209      113,615       29,864.3  pthread_create        \n",
            "      0.0          199,886         16       12,492.9        8,205.0      2,562       58,815       13,542.7  mmap                  \n",
            "      0.0          102,753          1      102,753.0      102,753.0    102,753      102,753            0.0  pthread_cond_wait     \n",
            "      0.0           80,935         39        2,075.3        1,860.0        873        7,534        1,277.3  fclose                \n",
            "      0.0           76,127          8        9,515.9        8,976.0      5,105       15,116        3,277.3  munmap                \n",
            "      0.0           74,456         46        1,618.6           55.5         48       38,619        6,270.7  fgets                 \n",
            "      0.0           62,445         12        5,203.8        5,596.5      1,240        9,775        2,644.8  write                 \n",
            "      0.0           38,553          6        6,425.5        6,059.0      1,784       11,022        3,399.2  open                  \n",
            "      0.0           37,386         17        2,199.2          107.0         58       20,102        5,166.4  fwrite                \n",
            "      0.0           34,863         64          544.7          557.0        188        1,336          182.4  fcntl                 \n",
            "      0.0           27,523         16        1,720.2        1,451.0        736        3,737          862.2  read                  \n",
            "      0.0           20,588          2       10,294.0       10,294.0      6,018       14,570        6,047.2  socket                \n",
            "      0.0           18,557          3        6,185.7        7,027.0      3,930        7,600        1,974.4  pipe2                 \n",
            "      0.0           13,492          1       13,492.0       13,492.0     13,492       13,492            0.0  connect               \n",
            "      0.0           11,232          2        5,616.0        5,616.0      2,247        8,985        4,764.5  pthread_cond_broadcast\n",
            "      0.0            7,347          1        7,347.0        7,347.0      7,347        7,347            0.0  fopen64               \n",
            "      0.0            4,099          4        1,024.8          814.5        613        1,857          563.5  putc                  \n",
            "      0.0            3,510          8          438.8          385.5        360          835          160.9  dup                   \n",
            "      0.0            1,712         20           85.6           44.0         38          573          125.2  fflush                \n",
            "      0.0            1,437          1        1,437.0        1,437.0      1,437        1,437            0.0  bind                  \n",
            "      0.0              986          1          986.0          986.0        986          986            0.0  listen                \n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_api_sum.py]... \n",
            "\n",
            " ** CUDA API Summary (cuda_api_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  ----------------------\n",
            "     95.5      105,745,289          2  52,872,644.5  52,872,644.5   135,836  105,609,453  74,581,109.8  cudaMalloc            \n",
            "      3.4        3,738,478          2   1,869,239.0   1,869,239.0    73,744    3,664,734   2,539,213.4  cudaMemcpy            \n",
            "      0.8          932,157          2     466,078.5     466,078.5   183,438      748,719     399,714.0  cudaFree              \n",
            "      0.1          155,220          1     155,220.0     155,220.0   155,220      155,220           0.0  cudaLaunchKernel      \n",
            "      0.1          139,891          1     139,891.0     139,891.0   139,891      139,891           0.0  cudaDeviceSynchronize \n",
            "      0.0            1,670          1       1,670.0       1,670.0     1,670        1,670           0.0  cuModuleGetLoadingMode\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_gpu_kern_sum.py]... \n",
            "\n",
            " ** CUDA GPU Kernel Summary (cuda_gpu_kern_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                         Name                       \n",
            " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  --------------------------------------------------\n",
            "    100.0          145,341          1  145,341.0  145,341.0   145,341   145,341          0.0  void reduce6<(int)256>(int *, int *, unsigned int)\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_gpu_mem_time_sum.py]... \n",
            "\n",
            " ** CUDA GPU MemOps Summary (by Time) (cuda_gpu_mem_time_sum):\n",
            "\n",
            " Time (%)  Total Time (ns)  Count   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)      Operation     \n",
            " --------  ---------------  -----  -----------  -----------  ---------  ---------  -----------  ------------------\n",
            "     99.8        3,489,587      1  3,489,587.0  3,489,587.0  3,489,587  3,489,587          0.0  [CUDA memcpy HtoD]\n",
            "      0.2            7,391      1      7,391.0      7,391.0      7,391      7,391          0.0  [CUDA memcpy DtoH]\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/cuda_gpu_mem_size_sum.py]... \n",
            "\n",
            " ** CUDA GPU MemOps Summary (by Size) (cuda_gpu_mem_size_sum):\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ------------------\n",
            "     16.777      1    16.777    16.777    16.777    16.777        0.000  [CUDA memcpy HtoD]\n",
            "      0.066      1     0.066     0.066     0.066     0.066        0.000  [CUDA memcpy DtoH]\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/openmp_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain OpenMP event data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/opengl_khr_range_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain KHR Extension (KHR_DEBUG) data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/opengl_khr_gpu_range_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain GPU KHR Extension (KHR_DEBUG) data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/vulkan_marker_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain Vulkan Debug Extension (Vulkan Debug Util) data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/vulkan_gpu_marker_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain GPU Vulkan Debug Extension (GPU Vulkan Debug markers) data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/dx11_pix_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain DX11 CPU debug markers.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/dx12_gpu_marker_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain DX12 GPU debug markers.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/dx12_pix_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain DX12 CPU debug markers.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/wddm_queue_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain WDDM context data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/um_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain CUDA Unified Memory CPU page faults data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/um_total_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain CUDA Unified Memory CPU page faults data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/um_cpu_page_faults_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain CUDA Unified Memory CPU page faults data.\n",
            "\n",
            "Processing [report1.sqlite] with [/usr/local/cuda-12.1/nsight-systems-2023.1.2/host-linux-x64/reports/openacc_sum.py]... \n",
            "SKIPPED: report1.sqlite does not contain OpenACC event data.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4lLY4c0sOnsd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}